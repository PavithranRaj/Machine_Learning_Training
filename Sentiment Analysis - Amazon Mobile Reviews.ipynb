{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study: Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dataset also requires cleaning text and removing unwanted tokens using regular expressions,\n",
    "# this part is not covered in this notebook to save time but strongly recommeded to perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Review Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>394349</th>\n",
       "      <td>Sony XPERIA Z2 D6503 FACTORY UNLOCKED Internat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>244.95</td>\n",
       "      <td>5</td>\n",
       "      <td>Very good one! Better than Samsung S and iphon...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34377</th>\n",
       "      <td>Apple iPhone 5c 8GB (Pink) - Verizon Wireless</td>\n",
       "      <td>Apple</td>\n",
       "      <td>194.99</td>\n",
       "      <td>1</td>\n",
       "      <td>The phone needed a SIM card, would have been n...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248521</th>\n",
       "      <td>Motorola Droid RAZR MAXX XT912 M Verizon Smart...</td>\n",
       "      <td>Motorola</td>\n",
       "      <td>174.99</td>\n",
       "      <td>5</td>\n",
       "      <td>I was 3 months away from my upgrade and my Str...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167661</th>\n",
       "      <td>CNPGD [U.S. Office Extended Warranty] Smartwat...</td>\n",
       "      <td>CNPGD</td>\n",
       "      <td>49.99</td>\n",
       "      <td>1</td>\n",
       "      <td>an experience i want to forget</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73287</th>\n",
       "      <td>Apple iPhone 7 Unlocked Phone 256 GB - US Vers...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>922.00</td>\n",
       "      <td>5</td>\n",
       "      <td>GREAT PHONE WORK ACCORDING MY EXPECTATIONS.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Product Name Brand Name   Price  \\\n",
       "394349  Sony XPERIA Z2 D6503 FACTORY UNLOCKED Internat...        NaN  244.95   \n",
       "34377       Apple iPhone 5c 8GB (Pink) - Verizon Wireless      Apple  194.99   \n",
       "248521  Motorola Droid RAZR MAXX XT912 M Verizon Smart...   Motorola  174.99   \n",
       "167661  CNPGD [U.S. Office Extended Warranty] Smartwat...      CNPGD   49.99   \n",
       "73287   Apple iPhone 7 Unlocked Phone 256 GB - US Vers...      Apple  922.00   \n",
       "\n",
       "        Rating                                            Reviews  \\\n",
       "394349       5  Very good one! Better than Samsung S and iphon...   \n",
       "34377        1  The phone needed a SIM card, would have been n...   \n",
       "248521       5  I was 3 months away from my upgrade and my Str...   \n",
       "167661       1                     an experience i want to forget   \n",
       "73287        5        GREAT PHONE WORK ACCORDING MY EXPECTATIONS.   \n",
       "\n",
       "        Review Votes  \n",
       "394349           0.0  \n",
       "34377            1.0  \n",
       "248521           3.0  \n",
       "167661           0.0  \n",
       "73287            1.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read in the data\n",
    "df = pd.read_csv('datasets/Amazon_Unlocked_Mobile.csv')\n",
    "\n",
    "# Sample the data to speed up computation\n",
    "# Comment out this line to match with lecture\n",
    "df = df.sample(frac=0.15, random_state=10)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62076, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62062, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Positively Rated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>394349</th>\n",
       "      <td>5</td>\n",
       "      <td>Very good one! Better than Samsung S and iphon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34377</th>\n",
       "      <td>1</td>\n",
       "      <td>The phone needed a SIM card, would have been n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248521</th>\n",
       "      <td>5</td>\n",
       "      <td>I was 3 months away from my upgrade and my Str...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167661</th>\n",
       "      <td>1</td>\n",
       "      <td>an experience i want to forget</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73287</th>\n",
       "      <td>5</td>\n",
       "      <td>GREAT PHONE WORK ACCORDING MY EXPECTATIONS.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277158</th>\n",
       "      <td>5</td>\n",
       "      <td>I fell in love with this phone because it did ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100311</th>\n",
       "      <td>5</td>\n",
       "      <td>I am pleased with this Blackberry phone! The p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251669</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product, best value for money smartphone...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374058</th>\n",
       "      <td>4</td>\n",
       "      <td>except samsung pay everything is good</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279878</th>\n",
       "      <td>5</td>\n",
       "      <td>I've bought 3 no problems. Fast delivery.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Rating                                            Reviews  \\\n",
       "394349       5  Very good one! Better than Samsung S and iphon...   \n",
       "34377        1  The phone needed a SIM card, would have been n...   \n",
       "248521       5  I was 3 months away from my upgrade and my Str...   \n",
       "167661       1                     an experience i want to forget   \n",
       "73287        5        GREAT PHONE WORK ACCORDING MY EXPECTATIONS.   \n",
       "277158       5  I fell in love with this phone because it did ...   \n",
       "100311       5  I am pleased with this Blackberry phone! The p...   \n",
       "251669       5  Great product, best value for money smartphone...   \n",
       "374058       4              except samsung pay everything is good   \n",
       "279878       5          I've bought 3 no problems. Fast delivery.   \n",
       "\n",
       "        Positively Rated  \n",
       "394349                 1  \n",
       "34377                  0  \n",
       "248521                 1  \n",
       "167661                 0  \n",
       "73287                  1  \n",
       "277158                 1  \n",
       "100311                 1  \n",
       "251669                 1  \n",
       "374058                 1  \n",
       "279878                 1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separating revivew and rating column\n",
    "df = df[[\"Rating\",\"Reviews\"]]\n",
    "# Drop missing values \n",
    "df.dropna(inplace=True)\n",
    "print(df.shape)\n",
    "\n",
    "\n",
    "# Remove any 'neutral' ratings equal to 3\n",
    "df = df[df['Rating'] != 3]\n",
    "# Encode 4s and 5s as 1 (rated positively)\n",
    "# Encode 1s and 2s as 0 (rated poorly)\n",
    "df['Positively Rated'] = np.where(df['Rating'] > 3, 1, 0)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.744958709429614"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most ratings are positive\n",
    "df['Positively Rated'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45821,)\n",
      "(11456,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Reviews'], \n",
    "                                                    df['Positively Rated'],\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify = df['Positively Rated'],\n",
    "                                                    random_state=0)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train first entry:\n",
      "\n",
      " pretty slow phone, snapchat was unusable and lagged. its a simple video app and if it cant handle it then that says a lot about the rest of the phone. returning it for a amazon giftcard\n",
      "\n",
      "\n",
      "X_train shape:  (45821,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train first entry:\\n\\n', X_train.iloc[0])\n",
    "print('\\n\\nX_train shape: ', X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Fit the CountVectorizer to the training data\n",
    "vect = CountVectorizer(lowercase=True,stop_words=\"english\").fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({'a',\n",
       "           'about',\n",
       "           'above',\n",
       "           'across',\n",
       "           'after',\n",
       "           'afterwards',\n",
       "           'again',\n",
       "           'against',\n",
       "           'all',\n",
       "           'almost',\n",
       "           'alone',\n",
       "           'along',\n",
       "           'already',\n",
       "           'also',\n",
       "           'although',\n",
       "           'always',\n",
       "           'am',\n",
       "           'among',\n",
       "           'amongst',\n",
       "           'amoungst',\n",
       "           'amount',\n",
       "           'an',\n",
       "           'and',\n",
       "           'another',\n",
       "           'any',\n",
       "           'anyhow',\n",
       "           'anyone',\n",
       "           'anything',\n",
       "           'anyway',\n",
       "           'anywhere',\n",
       "           'are',\n",
       "           'around',\n",
       "           'as',\n",
       "           'at',\n",
       "           'back',\n",
       "           'be',\n",
       "           'became',\n",
       "           'because',\n",
       "           'become',\n",
       "           'becomes',\n",
       "           'becoming',\n",
       "           'been',\n",
       "           'before',\n",
       "           'beforehand',\n",
       "           'behind',\n",
       "           'being',\n",
       "           'below',\n",
       "           'beside',\n",
       "           'besides',\n",
       "           'between',\n",
       "           'beyond',\n",
       "           'bill',\n",
       "           'both',\n",
       "           'bottom',\n",
       "           'but',\n",
       "           'by',\n",
       "           'call',\n",
       "           'can',\n",
       "           'cannot',\n",
       "           'cant',\n",
       "           'co',\n",
       "           'con',\n",
       "           'could',\n",
       "           'couldnt',\n",
       "           'cry',\n",
       "           'de',\n",
       "           'describe',\n",
       "           'detail',\n",
       "           'do',\n",
       "           'done',\n",
       "           'down',\n",
       "           'due',\n",
       "           'during',\n",
       "           'each',\n",
       "           'eg',\n",
       "           'eight',\n",
       "           'either',\n",
       "           'eleven',\n",
       "           'else',\n",
       "           'elsewhere',\n",
       "           'empty',\n",
       "           'enough',\n",
       "           'etc',\n",
       "           'even',\n",
       "           'ever',\n",
       "           'every',\n",
       "           'everyone',\n",
       "           'everything',\n",
       "           'everywhere',\n",
       "           'except',\n",
       "           'few',\n",
       "           'fifteen',\n",
       "           'fifty',\n",
       "           'fill',\n",
       "           'find',\n",
       "           'fire',\n",
       "           'first',\n",
       "           'five',\n",
       "           'for',\n",
       "           'former',\n",
       "           'formerly',\n",
       "           'forty',\n",
       "           'found',\n",
       "           'four',\n",
       "           'from',\n",
       "           'front',\n",
       "           'full',\n",
       "           'further',\n",
       "           'get',\n",
       "           'give',\n",
       "           'go',\n",
       "           'had',\n",
       "           'has',\n",
       "           'hasnt',\n",
       "           'have',\n",
       "           'he',\n",
       "           'hence',\n",
       "           'her',\n",
       "           'here',\n",
       "           'hereafter',\n",
       "           'hereby',\n",
       "           'herein',\n",
       "           'hereupon',\n",
       "           'hers',\n",
       "           'herself',\n",
       "           'him',\n",
       "           'himself',\n",
       "           'his',\n",
       "           'how',\n",
       "           'however',\n",
       "           'hundred',\n",
       "           'i',\n",
       "           'ie',\n",
       "           'if',\n",
       "           'in',\n",
       "           'inc',\n",
       "           'indeed',\n",
       "           'interest',\n",
       "           'into',\n",
       "           'is',\n",
       "           'it',\n",
       "           'its',\n",
       "           'itself',\n",
       "           'keep',\n",
       "           'last',\n",
       "           'latter',\n",
       "           'latterly',\n",
       "           'least',\n",
       "           'less',\n",
       "           'ltd',\n",
       "           'made',\n",
       "           'many',\n",
       "           'may',\n",
       "           'me',\n",
       "           'meanwhile',\n",
       "           'might',\n",
       "           'mill',\n",
       "           'mine',\n",
       "           'more',\n",
       "           'moreover',\n",
       "           'most',\n",
       "           'mostly',\n",
       "           'move',\n",
       "           'much',\n",
       "           'must',\n",
       "           'my',\n",
       "           'myself',\n",
       "           'name',\n",
       "           'namely',\n",
       "           'neither',\n",
       "           'never',\n",
       "           'nevertheless',\n",
       "           'next',\n",
       "           'nine',\n",
       "           'no',\n",
       "           'nobody',\n",
       "           'none',\n",
       "           'noone',\n",
       "           'nor',\n",
       "           'not',\n",
       "           'nothing',\n",
       "           'now',\n",
       "           'nowhere',\n",
       "           'of',\n",
       "           'off',\n",
       "           'often',\n",
       "           'on',\n",
       "           'once',\n",
       "           'one',\n",
       "           'only',\n",
       "           'onto',\n",
       "           'or',\n",
       "           'other',\n",
       "           'others',\n",
       "           'otherwise',\n",
       "           'our',\n",
       "           'ours',\n",
       "           'ourselves',\n",
       "           'out',\n",
       "           'over',\n",
       "           'own',\n",
       "           'part',\n",
       "           'per',\n",
       "           'perhaps',\n",
       "           'please',\n",
       "           'put',\n",
       "           'rather',\n",
       "           're',\n",
       "           'same',\n",
       "           'see',\n",
       "           'seem',\n",
       "           'seemed',\n",
       "           'seeming',\n",
       "           'seems',\n",
       "           'serious',\n",
       "           'several',\n",
       "           'she',\n",
       "           'should',\n",
       "           'show',\n",
       "           'side',\n",
       "           'since',\n",
       "           'sincere',\n",
       "           'six',\n",
       "           'sixty',\n",
       "           'so',\n",
       "           'some',\n",
       "           'somehow',\n",
       "           'someone',\n",
       "           'something',\n",
       "           'sometime',\n",
       "           'sometimes',\n",
       "           'somewhere',\n",
       "           'still',\n",
       "           'such',\n",
       "           'system',\n",
       "           'take',\n",
       "           'ten',\n",
       "           'than',\n",
       "           'that',\n",
       "           'the',\n",
       "           'their',\n",
       "           'them',\n",
       "           'themselves',\n",
       "           'then',\n",
       "           'thence',\n",
       "           'there',\n",
       "           'thereafter',\n",
       "           'thereby',\n",
       "           'therefore',\n",
       "           'therein',\n",
       "           'thereupon',\n",
       "           'these',\n",
       "           'they',\n",
       "           'thick',\n",
       "           'thin',\n",
       "           'third',\n",
       "           'this',\n",
       "           'those',\n",
       "           'though',\n",
       "           'three',\n",
       "           'through',\n",
       "           'throughout',\n",
       "           'thru',\n",
       "           'thus',\n",
       "           'to',\n",
       "           'together',\n",
       "           'too',\n",
       "           'top',\n",
       "           'toward',\n",
       "           'towards',\n",
       "           'twelve',\n",
       "           'twenty',\n",
       "           'two',\n",
       "           'un',\n",
       "           'under',\n",
       "           'until',\n",
       "           'up',\n",
       "           'upon',\n",
       "           'us',\n",
       "           'very',\n",
       "           'via',\n",
       "           'was',\n",
       "           'we',\n",
       "           'well',\n",
       "           'were',\n",
       "           'what',\n",
       "           'whatever',\n",
       "           'when',\n",
       "           'whence',\n",
       "           'whenever',\n",
       "           'where',\n",
       "           'whereafter',\n",
       "           'whereas',\n",
       "           'whereby',\n",
       "           'wherein',\n",
       "           'whereupon',\n",
       "           'wherever',\n",
       "           'whether',\n",
       "           'which',\n",
       "           'while',\n",
       "           'whither',\n",
       "           'who',\n",
       "           'whoever',\n",
       "           'whole',\n",
       "           'whom',\n",
       "           'whose',\n",
       "           'why',\n",
       "           'will',\n",
       "           'with',\n",
       "           'within',\n",
       "           'without',\n",
       "           'would',\n",
       "           'yet',\n",
       "           'you',\n",
       "           'your',\n",
       "           'yours',\n",
       "           'yourself',\n",
       "           'yourselves'})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_stop_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26762"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " 'africa_en',\n",
       " 'boggingly',\n",
       " 'conned',\n",
       " 'dogs',\n",
       " 'fintie',\n",
       " 'honesty',\n",
       " 'legit',\n",
       " 'nervious',\n",
       " 'political',\n",
       " 'resetearlo',\n",
       " 'snob',\n",
       " 'tlf',\n",
       " 'whine']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_feature_names()[::2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26762"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<45821x26762 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 713064 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform the documents in the training data to a document-term matrix\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "X_train_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anshu\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the transformed test documents\n",
    "predictions = model.predict(vect.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9285963687150838"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(vect.transform(X_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.82      0.85      2922\n",
      "           1       0.94      0.97      0.95      8534\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     11456\n",
      "   macro avg       0.92      0.89      0.90     11456\n",
      "weighted avg       0.93      0.93      0.93     11456\n",
      "\n",
      "[[2395  527]\n",
      " [ 291 8243]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test,predictions))\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs:\n",
      "['worst' 'waste' 'terrible' 'junk' 'horrible' 'giving' 'sporadically'\n",
      " 'disappointed' 'garbage' 'poor']\n",
      "\n",
      "[-3.32554693 -3.22045649 -2.69516823 -2.62160901 -2.60042396 -2.44763633\n",
      " -2.43529051 -2.42623447 -2.38153229 -2.31428968]\n",
      "Largest Coefs: \n",
      "['excelente' 'excelent' 'excellent' 'loves' 'perfectly' 'love' 'perfect'\n",
      " 'exactly' 'exelente' 'awesome']\n",
      "[4.11012515 3.8926866  3.8367847  3.46067662 3.21957061 3.15442984\n",
      " 3.07320681 2.87318863 2.83225314 2.67304628]\n"
     ]
    }
   ],
   "source": [
    "# get the feature names as numpy array\n",
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "# Sort the coefficients from the model\n",
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "\n",
    "# Find the 10 smallest and 10 largest coefficients\n",
    "# The 10 largest coefficients are being indexed using [:-11:-1] \n",
    "# so the list returned is in order of largest to smallest\n",
    "print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "print(model.coef_[0][sorted_coef_index[:10]])\n",
    "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))\n",
    "print(model.coef_[0][sorted_coef_index[:-11:-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7752"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Fit the TfidfVectorizer to the training data specifiying a minimum document frequency of 5\n",
    "vect = TfidfVectorizer(min_df=5).fit(X_train)\n",
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.88      2922\n",
      "           1       0.95      0.97      0.96      8534\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     11456\n",
      "   macro avg       0.93      0.91      0.92     11456\n",
      "weighted avg       0.94      0.94      0.94     11456\n",
      "\n",
      "[[2484  438]\n",
      " [ 261 8273]]\n"
     ]
    }
   ],
   "source": [
    "X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "\n",
    "print(classification_report(y_test,predictions))\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest tfidf:\n",
      "['chemicals' 'kcal' 'vibratethe' 'verbatim' '320mah' 'corrosive' 'oblong'\n",
      " 'disassembly' 'callsaccessories' 'benzene']\n",
      "\n",
      "Largest tfidf: \n",
      "['sweet' 'stars' 'star' 'ideal' 'fraud' 'venta' 'excellente' 'excellent'\n",
      " 'mm' 'excelentes']\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "sorted_tfidf_index = X_train_vectorized.max(0).toarray()[0].argsort()\n",
    "\n",
    "print('Smallest tfidf:\\n{}\\n'.format(feature_names[sorted_tfidf_index[:10]]))\n",
    "print('Largest tfidf: \\n{}'.format(feature_names[sorted_tfidf_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs:\n",
      "['not' 'disappointed' 'worst' 'slow' 'return' 'waste' 'terrible' 'doesn'\n",
      " 'horrible' 'poor']\n",
      "\n",
      "Largest Coefs: \n",
      "['great' 'love' 'excellent' 'perfect' 'best' 'good' 'perfectly' 'amazing'\n",
      " 'awesome' 'easy']\n"
     ]
    }
   ],
   "source": [
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "\n",
    "print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]\n"
     ]
    }
   ],
   "source": [
    "# These reviews are treated the same by our current model\n",
    "print(model.predict(vect.transform(['not an issue, phone is working',\n",
    "                                    'an issue, phone is not working'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51591"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the CountVectorizer to the training data specifiying a minimum \n",
    "# document frequency of 5 and extracting 1-grams and 2-grams\n",
    "vect = CountVectorizer(min_df=5, ngram_range=(1,2)).fit(X_train)\n",
    "\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " 'assigned',\n",
       " 'commands',\n",
       " 'features which',\n",
       " 'hundred dollar',\n",
       " 'looks very',\n",
       " 'oh my',\n",
       " 'questions',\n",
       " 'staring at',\n",
       " 'to life',\n",
       " 'with expandable']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_feature_names()[::5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.90      2922\n",
      "           1       0.96      0.97      0.97      8534\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     11456\n",
      "   macro avg       0.94      0.93      0.93     11456\n",
      "weighted avg       0.95      0.95      0.95     11456\n",
      "\n",
      "[[2595  327]\n",
      " [ 240 8294]]\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "\n",
    "print(classification_report(y_test,predictions))\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs:\n",
      "['no good' 'junk' 'not good' 'horrible' 'poor' 'worst' 'not very'\n",
      " 'terrible' 'sucks' 'waste']\n",
      "\n",
      "Largest Coefs: \n",
      "['excellent' 'excelente' 'excelent' 'perfect' 'not bad' 'great' 'awesome'\n",
      " 'love' 'no problems' 'exelente']\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "\n",
    "print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]\n"
     ]
    }
   ],
   "source": [
    "# These reviews are now correctly identified\n",
    "print(model.predict(vect.transform(['not an issue, phone is working',\n",
    "                                    'an issue, phone is not working'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import models,layers\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57277,)\n",
      "(57277,)\n"
     ]
    }
   ],
   "source": [
    "x= df['Reviews']\n",
    "y = df['Positively Rated']\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 31508 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# The maximum number of words to be used. (most frequent)\n",
    "MAX_NB_WORDS = 20000\n",
    "# Max number of words in each complaint.\n",
    "MAX_SEQUENCE_LENGTH = 250\n",
    "# This is fixed.\n",
    "EMBEDDING_DIM = 120\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', \n",
    "                      lower=True)\n",
    "\n",
    "tokenizer.fit_on_texts(x.values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (57277, 250)\n"
     ]
    }
   ],
   "source": [
    "# replace the words in the document by their index to give an array \n",
    "# of numbers \n",
    "x = tokenizer.texts_to_sequences(x.values)\n",
    "# truncating the documents/sequences with a fixed length of 250\n",
    "x = pad_sequences(x, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51549, 250) (51549,)\n",
      "(5728, 250) (5728,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(x,y, test_size = 0.10, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 51549 samples, validate on 5728 samples\n",
      "Epoch 1/10\n",
      "51549/51549 [==============================] - 116s 2ms/step - loss: 0.4877 - acc: 0.7694 - val_loss: 0.3337 - val_acc: 0.8561\n",
      "Epoch 2/10\n",
      "51549/51549 [==============================] - 116s 2ms/step - loss: 0.2339 - acc: 0.9070 - val_loss: 0.1809 - val_acc: 0.9344\n",
      "Epoch 3/10\n",
      "51549/51549 [==============================] - 121s 2ms/step - loss: 0.1634 - acc: 0.9417 - val_loss: 0.1674 - val_acc: 0.9410\n",
      "Epoch 4/10\n",
      "51549/51549 [==============================] - 108s 2ms/step - loss: 0.1345 - acc: 0.9531 - val_loss: 0.1601 - val_acc: 0.9422\n",
      "Epoch 5/10\n",
      "51549/51549 [==============================] - 110s 2ms/step - loss: 0.1178 - acc: 0.9590 - val_loss: 0.1601 - val_acc: 0.9476\n",
      "Epoch 6/10\n",
      "51549/51549 [==============================] - 109s 2ms/step - loss: 0.1057 - acc: 0.9643 - val_loss: 0.1661 - val_acc: 0.9447\n",
      "Epoch 7/10\n",
      "51549/51549 [==============================] - 126s 2ms/step - loss: 0.1008 - acc: 0.9660 - val_loss: 0.1566 - val_acc: 0.9457\n",
      "Epoch 8/10\n",
      "51549/51549 [==============================] - 122s 2ms/step - loss: 0.0916 - acc: 0.9698 - val_loss: 0.1700 - val_acc: 0.9454\n",
      "Epoch 9/10\n",
      "51549/51549 [==============================] - 93s 2ms/step - loss: 0.0845 - acc: 0.9728 - val_loss: 0.1684 - val_acc: 0.9473\n",
      "Epoch 10/10\n",
      "51549/51549 [==============================] - 93s 2ms/step - loss: 0.0793 - acc: 0.9741 - val_loss: 0.1707 - val_acc: 0.9450\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=x.shape[1]))\n",
    "model.add(layers.SpatialDropout1D(0.2))\n",
    "model.add(layers.LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, Y_train, epochs=10, batch_size=1000,validation_data=(X_test,Y_test),\n",
    "                    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5728/5728 [==============================] - 63s 11ms/step\n",
      "Test set\n",
      "  Loss: 0.171\n",
      "  Accuracy: 0.945\n"
     ]
    }
   ],
   "source": [
    "loss,accr = model.evaluate(X_test,Y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(loss,accr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.90      1511\n",
      "           1       0.96      0.96      0.96      4217\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      5728\n",
      "   macro avg       0.93      0.93      0.93      5728\n",
      "weighted avg       0.94      0.95      0.94      5728\n",
      "\n",
      "[[1348  163]\n",
      " [ 152 4065]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_classes(X_test)\n",
    "print(classification_report(Y_test,predictions))\n",
    "print(confusion_matrix(Y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title('Loss')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Accuracy')\n",
    "plt.plot(history.history['acc'], label='train')\n",
    "plt.plot(history.history['val_acc'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip = [['not an issue, phone is working'],['an issue, phone is not working']]\n",
    "ip = tokenizer.texts_to_sequences(ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 250)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ip = pad_sequences(ip,maxlen=250)\n",
    "ip.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
